\documentclass[a4paper,12pt]{article}

% --- Essential Packages ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{parskip}
\usepackage{pgfplots}

% --- Page Configuration ---
\geometry{margin=2.5cm, top=3cm, bottom=3cm}

% --- Color Scheme (Standard Black/White) ---
\definecolor{codegray}{gray}{0.95}

% --- Hyperlink Configuration ---
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    urlcolor=black,
    citecolor=black,
    pdftitle={Technical Report - Concurrent HTTP Web Server},
    pdfauthor={Martim Gil, Nuno Leite Faria}
}

% --- Code Style ---
\lstset{
    backgroundcolor=\color{codegray},
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    framerule=0.5pt,
    rulecolor=\color{black},
    numbers=left,
    captionpos=b,
    keywordstyle=\bfseries,
    commentstyle=\itshape,
    stringstyle=\ttfamily,
    showstringspaces=false,
    tabsize=4,
    xleftmargin=1em,
    xrightmargin=1em,
    aboveskip=1em,
    belowskip=1em,
    language=C
}

% --- Header and Footer ---
\setlength{\headheight}{14pt}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small\textit{Concurrent HTTP Web Server}}
\fancyhead[R]{\small\textit{Technical Report}}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0pt}

% --- Section Styling ---
\titleformat{\section}{\Large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\large\bfseries}{\thesubsection}{1em}{}
\titleformat{\subsubsection}{\normalsize\bfseries}{\thesubsubsection}{1em}{}

% --- List Styling ---
\setlist[itemize]{noitemsep, topsep=0.5em}
\setlist[enumerate]{noitemsep, topsep=0.5em}

\begin{document}

% =================================================================
% TITLE PAGE
% =================================================================
\begin{titlepage}
    \centering
    
    % --- DETI Logo ---
    \vspace*{2cm}
    \includegraphics[width=0.7\textwidth]{deti.png}
    
    \vspace{3cm}
    
    % --- Document Title ---
    {\Huge\textbf{Technical Report}}\\[0.5cm]
    {\LARGE Multi-Threaded Web Server with IPC and Semaphores}
    
    \vspace{1.5cm}
    
    % --- Decorative Line ---
    \rule{0.6\textwidth}{0.5pt}
    
    \vspace{1.5cm}
    
    % --- Course Information ---
    {\Large\textbf{Operating Systems}}\\[0.3cm]
    {\large Academic Year 2024/2025}
    
    \vspace{2cm}
    
    % --- Authors ---
    \begin{tabular}{cc}
        \textbf{Martim Gil} & \textbf{Nuno Leite Faria} \\
        Student ID: 124833 & Student ID: 112994 \\
    \end{tabular}
    
    \vspace{1.5cm}
    
    % --- Supervisor ---
    {\large Supervisor: Prof. Pedro Azevedo Fernandes}
    
    \vfill
    
    % --- Date ---
    {\large \today}
    
\end{titlepage}

\begin{abstract}
    This document outlines the design, implementation, and evaluation of a concurrent HTTP server built in C for the Operating Systems course at the University of Aveiro.
    The primary objective was to develop a system capable of effectively managing numerous client requests simultaneously using a hybrid process–thread architecture.
    
    The system incorporates sophisticated synchronization and interprocess communication methods, specifically POSIX semaphores and shared memory, guaranteeing consistency and mutual exclusion during access to shared resources. Additional modules were implemented for safe concurrent logging, LRU-based file caching, and real-time statistics monitoring.
    
    The final solution underwent extensive functional, concurrency, and stress testing. The results demonstrate the reliability, scalability, and correctness of the synchronization mechanisms, as well as the system's ability to maintain consistent performance under high workloads.
\end{abstract}

\tableofcontents
\newpage

% ----------------------------------------------------------------------
% 1. Introduction
% ----------------------------------------------------------------------
\section{Introduction}

Creating concurrent servers is among the most effective and demonstrative uses of synchronization, inter-process communication, and thread management concepts explored in operating systems courses. This project focused on creating and deploying a straightforward yet robust HTTP server that can handle multiple concurrent client requests simultaneously.

The C programming language was used for the system's implementation, utilizing POSIX system calls for thread creation and synchronization, semaphore management, shared memory management, and inter-process communication. The structure adopts a modular design to guarantee the maintainability and extensibility of various system elements.

% ----------------------------------------------------------------------
% 2. Implementation Details
% ----------------------------------------------------------------------
\section{Implementation Details}

The concurrent web server was implemented entirely in C using POSIX system calls for process management, thread creation, synchronization, and interprocess communication (IPC). The implementation follows a modular architecture where each subsystem corresponds to a dedicated source file in the \texttt{src/} directory. This structure promotes reusability, maintainability, and clear separation of concerns between the networking layer, synchronization mechanisms, and data management components.

\subsection{System Architecture}

At a high level, the project consists of three main execution entities: the \textbf{master process}, the \textbf{worker threads}, and the \textbf{auxiliary tools}.  
The master process is responsible for system initialization, socket setup, configuration parsing, and coordination of shared resources.  
Each worker thread, managed by a thread pool, handles an individual client connection.  
Auxiliary programs, such as \texttt{stats\_reader}, access the server's shared memory region to retrieve runtime statistics without interfering with normal operation.

The core modules include:
\begin{itemize}
  \item \textbf{master.c} – Initializes the system, loads configuration, and manages the main listening loop.
  \item \textbf{worker.c / worker.h} – Implements the logic executed by each worker thread.
  \item \textbf{thread\_pool.c / .h} – Manages the pool of worker threads and the task queue.
  \item \textbf{cache.c / .h} – Provides an in-memory LRU file cache.
  \item \textbf{logger.c / .h} – Implements thread-safe logging.
  \item \textbf{stats.c / .h} – Manages global statistics in shared memory.
  \item \textbf{semaphores.c / .h} – Encapsulates POSIX semaphore operations.
  \item \textbf{http\_parser.c / http\_builder.c} – Handle HTTP protocol parsing and response construction.
\end{itemize}

\subsection{Process and Thread Management}
The concurrent HTTP server follows a hybrid process--thread architecture. The \texttt{master} process is responsible for system initialization and the creation of a fixed-size thread pool. This approach avoids the overhead associated with creating and destroying threads on demand while allowing high levels of concurrency.

Once initialized, the \texttt{master} process accepts incoming TCP connections and submits them to the thread pool. The thread pool, implemented in \texttt{src/thread\_pool.c}, maintains a synchronized queue of tasks. Worker threads wait on a condition variable; when a new connection is enqueued, a thread is signaled to wake up and process the request.

\subsection{Synchronization and IPC}
To guarantee secure operation in a multithreaded setting, the system uses POSIX semaphores, mutexes, and shared memory.

\paragraph{Producer--Consumer Coordination.}
The interaction between the master and worker threads follows a producer--consumer model. The master produces tasks (socket descriptors), and workers consume them. Access to the task queue is controlled by a counting semaphore (available tasks) and a mutex (queue integrity).

\paragraph{Shared Statistics.}
Global runtime metrics (requests, bytes sent, cache hits) are stored in POSIX shared memory. Updates to these counters are protected by binary semaphores to ensure atomicity, preventing race conditions where multiple threads could try to increment the same counter simultaneously.

\paragraph{Shared Logging.}
Logging operations utilize a named binary semaphore to ensure mutual exclusion. This prevents "interleaved" log lines where output from multiple threads would otherwise be mixed together in the file.

\subsection{Resource Management (Cache)}
To minimize disk I/O, the server incorporates an LRU (Least Recently Used) in-memory cache (\texttt{src/cache.c}).
The cache uses \textbf{POSIX reader–writer locks} (\texttt{pthread\_rwlock\_t}) to maximize concurrency. Multiple threads can read from the cache simultaneously (read lock), but writing to the cache (loading a new file) requires exclusive access (write lock). This significantly improves performance under high read loads compared to a simple mutex.

\subsection{HTTP Processing}
The HTTP processing layer is split between parsing and response generation:

% Request parsing and response construction.
% Error handling (404, 403, 500).
% Reference: src/http_parser.c, src/http_builder.c

% ----------------------------------------------------------------------
% 3. Challenges and Solutions
% ----------------------------------------------------------------------
\section{Challenges and Solutions}

The development of a concurrent HTTP server presented challenges related to synchronization, communication, and system scalability.

\subsection{Race Conditions}
During early development, race conditions in the shared statistics subsystem caused lost counts. The solution was the introduction of an \textbf{exclusive binary semaphore} to protect the shared \texttt{stats} structure. This ensures that only one thread can modify the statistics at any given time, guaranteeing atomicity. Verification through stress tests confirmed that the reported request counts matched the actual number of served requests.

\subsection{Memory Management and Leaks}
Memory management was critical for stability. \textbf{Valgrind} was used extensively to detect leaks. Issues with unreleased cache buffers and unclosed file descriptors were corrected.
To ensure shared memory and semaphores are cleaned up even after a forced termination (\texttt{Ctrl+C}), the master process installs custom signal handlers for \texttt{SIGINT} and \texttt{SIGTERM}. These handlers invoke a cleanup routine that unlinks all semaphores and unmaps shared memory, preventing orphaned resources in the OS.

\subsection{Log Synchronization}
Concurrent writing to the log file initially resulted in interleaved/garbled text. The solution involved using a \textbf{named binary semaphore} for the log file and implementing thread-local buffering. Threads format their complete log message into a local buffer first, then acquire the semaphore, write the entire buffer in one operation, and release the semaphore.

\subsection{Zombies and Signals}
To prevent zombie processes (defunct child processes), the master process handles the \texttt{SIGCHLD} signal. The handler uses \texttt{waitpid(-1, NULL, WNOHANG)} to immediately reap any terminated worker processes, keeping the process table clean.

% ----------------------------------------------------------------------
% 4. Testing Methodology
% ----------------------------------------------------------------------
\section{Testing Methodology}

Validation was performed through a structured framework combining automated functional tests and concurrency stress tests.

\subsection{Functional Tests}
The \texttt{tests/test\_suite.sh} script verifies HTTP compliance using \texttt{curl}. It checks for correct status codes (200, 404, 500), proper MIME types, and handling of special files. All functional tests passed consistently.

\subsection{Concurrency and Stress Tests}
Concurrency was validated using:
\begin{itemize}
    \item \textbf{ApacheBench (ab):} Simulating up to 100 concurrent clients to measure throughput and latency.
    \item \textbf{Helgrind \& ThreadSanitizer:} Dynamic analysis tools used to detect data races. These tools confirmed that our synchronization primitives (mutexes, rwlocks) effectively protected shared data.
    \item \textbf{Stress Script:} A custom script sending random requests for extended periods to check for memory leaks or long-term instability.
\end{itemize}

% ----------------------------------------------------------------------
% 5. Performance Analysis
% ----------------------------------------------------------------------
\section{Performance Analysis}

\subsection{Test Environment}
\subsection{Test Environment}
% Hardware used (CPU, RAM), OS.
% Server configuration (N Workers, M Threads).

\subsection{Results: Throughput}
% Graph: Requests per Second vs Number of Concurrent Clients.
% Ex: Test with 10, 50, 100, 500 clients.

\subsection{Results: Latency}
% Average response time.

\subsection{Discussion of Results}
% Interpretation: "Cache improved performance by 300%..."
% "The main bottleneck appears to be log writing..."
% ----------------------------------------------------------------------

% ----------------------------------------------------------------------
% 6. Conclusion
% ----------------------------------------------------------------------
\section{Conclusion}
% Summary of work.
% Does the server meet all requirements?
% Future Work (e.g., Keep-Alive, SSL).

\end{document}